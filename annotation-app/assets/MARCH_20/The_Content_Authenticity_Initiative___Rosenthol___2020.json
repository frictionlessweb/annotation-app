{"title":"The_Content_Authenticity_Initiative___Rosenthol___2020","questions":{"topicTask":[{"id":0,"text":"CAI"},{"id":1,"text":"XMP"},{"id":2,"text":"Digital Signatures"},{"id":3,"text":"Composed Documents"},{"id":4,"text":"Digital Content Attribution"}],"questionTask":[{"id":5,"text":"What is CAI and what is its purpose in digital content attribution?"},{"id":10,"text":"What are some of the challenges to trust in media and how does CAI address them?"},{"id":15,"text":"How does the CAI assertion and claim model allow for any type of assertion to be added at any time?"}],"statementsTask":[{"id":7,"text":"CAI stands for Content Authenticity Initiative. Its purpose is to develop industry standards for content attribution, which includes creating a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio), and streaming content. The CAI aims to help content consumers make more informed decisions about what to trust by augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be. The creative chooses distribution points that support the CAI to ensure their attribution information remains intact. As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution. The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling. CAI specifications must respect the common privacy concerns of creators, publishers, and consumers of content. Since CAI data can contain a depth of detail that is not always relevant for all viewers, a UX based on the idea of progressive disclosure is envisaged. It is important for users to understand how CAI works, what the disclosed information means, and more.\n\nSources:\n[0] The initial mission of the CAI is to develop the industry standard for content attribution.\n[1] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[2] The creative chooses distribution points that support the CAI to ensure their attribution information remains intact.\n[3] As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution.\n[4] The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling.\n[5] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[6] CAI specifications must respect the common privacy concerns of creators, publishers and consumers of content.","system":"gpt_retrieval"},{"id":9,"text":"The Content Authenticity Initiative (CAI) is a set of standards for digital content attribution that was announced by Adobe in partnership with The New York Times Company and Twitter [1]. The purpose of CAI is to provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today [2]. By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust [3]. The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content [4]. The CAI leverages existing standards for encoding, hashing, signing, compression and metadata, and allows for the redaction of assertions in a verifiable way that is also part of the provenance of the asset [5] [6] [7]. The CAI provides a specific type of assertion that references each ingredient's claims and assertions, whether they are embedded into the new composed document or stored in the cloud, and employs digital signature technology to ensure the integrity of the CAI information that is embedded into an asset, including the asset's data itself [8] [9]. The purpose of CAI is to establish trust and transparency in media by creating a rich, verifiable context that amplifies confidence in the authenticity of the asset [10] [11].\n\nSources:\n[1] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[2] We will provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today.\n[3] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[4] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[5] The CAI embraces existing standards.\n[6] This includes standards for encoding , hashing, signing, compression and metadata.\n[7] The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset.\n[8] The CAI provides for this with a specific type of assertion that references each ingredient’s claims and assertions, whether they are embedded into the new composed document or stored in the cloud.\n[9] In order to ensure the integrity of the CAI information that is embedded into an asset, including the asset’s data itself, (<https://en.wikipedia.org/wiki/Digital_signature>)digital signature technology is employed.\n[10] Together this collection of CAI data creates a rich, verifiable context that amplifies confidence in the authenticity of the asset.\n[11] With this first step towards an industry standard for digital content attribution, we look optimistically to a future with more trust and transparency in media."},{"id":12,"text":"The sources suggest that there are extraordinary challenges to trust in media. To increase trust in media, it is important to engage diverse communities. The CAI aims to help content consumers make more informed decisions about what to trust by augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be. The CAI presents a set of standards that can be used to create and reveal attribution and history for various types of media. The CAI ecosystem is built around its own CAI Trust List for establishing trust. CAI claims can be augmented with human-generated review assertions so that fact-checking professionals can provide additional evidence of authenticity. The initial mission of the CAI is to develop the industry standard for content attribution. Since CAI data can contain a depth of detail that is not always relevant for all viewers, a UX based on the idea of progressive disclosure is envisaged.\n\nSources:\n[0] We are witnessing extraordinary challenges to trust in media.\n[1] Increasing trust in media requires the ongoing engagement of diverse communities.\n[2] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[3] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[4] To address these concerns, the CAI ecosystem is built around its own CAI Trust List for (<>)“Establishing Trust”.\n[5] CAI claims can be augmented with human-generated review assertions so that fact checking professionals can provide additional evidence of authenticity.\n[6] The initial mission of the CAI is to develop the industry standard for content attribution.","system":"gpt_retrieval"},{"id":14,"text":"According to sources [1] [2] [3], there are growing challenges to trust in media due to the increasing velocity of digital content and the democratization of powerful creation and editing techniques. Social platforms also amplify the reach and influence of certain content via ever more complex and opaque algorithms, leading to mis-attributed and mis-contextualized content that spreads quickly [4]. The Content Authenticity Initiative (CAI), announced by Adobe in partnership with The New York Times Company and Twitter, aims to address these challenges by providing robust content attribution to ensure transparency, understanding, and ultimately, trust [5] [6] [7]. The CAI provides metadata that comprises information regarding asset creation, authorship, edit actions, capture device details, software used, and many other subjects [8]. This metadata creates a rich, verifiable context that amplifies confidence in the authenticity of the asset [9]. As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution [10]. A key point of differentiation for the asset with CAI information is that it empowers the source, rather than the institutions publishing the asset, to be the trusted entity [11]. By embracing ClaimReview and other standards like it, the CAI will support fact checking with rich metadata to optimize verification workflows [12]. The CAI assertion and claim model allows for any type of assertion to be added at any time, which addresses concerns about adding identity or any other form of identifying attribution to an asset at the time of capture that could lead to increased risk to content producers or others [13] [14]. While the CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator, trusted timestamps can be used to cast doubt on assets with deliberately altered histories [15] [16].\n\nSources:\n[1] We are witnessing extraordinary challenges to trust in media.\n[2] As social platforms amplify the reach and influence of certain content via ever more complex and opaque algorithms, mis-attributed and mis-contextualized content spreads quickly.\n[3] The news media industry is facing a growing sense of distrust in digital media and a changing distribution system as the number of people who receive news from social and nontraditional media sources grows.\n[4] As social platforms amplify the reach and influence of certain content via ever more complex and opaque algorithms, mis-attributed and mis-contextualized content spreads quickly.\n[5] With the increasing velocity of digital content and the democratization of powerful creation and editing techniques, robust content attribution is critical to ensure transparency, understanding, and ultimately, trust.\n[6] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[7] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[8] This metadata comprises information regarding asset creation, authorship, edit actions, capture device details, software used and many other subjects.\n[9] Together this collection of CAI data creates a rich, verifiable context that amplifies confidence in the authenticity of the asset.\n[10] As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution.\n[11] A key point of differentiation for the asset with CAI information is that it empowers the source, rather than the institutions publishing the asset, to be the trusted entity.\n[12] By embracing ClaimReview and other standards like it, the CAI will support fact checking with rich metadata to optimize verification workflows.\n[13] In cases where adding identity (or any other form of identifying attribution) to an asset at the time of capture could lead to increased risk to content producers or others, it is important that assertions and claims can be added at some later time.\n[14] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[15] An actor could use watermarking technology to durably embed information (either perceptibly or imperceptibly) about the asset’s current claim.\n[16] Trusted timestamps can be used to cast doubt on assets with deliberately altered histories."},{"id":17,"text":"The CAI assertion and claim model allows for any type of assertion to be added at any time. Additionally, the CAI claims can be augmented with human-generated review assertions to provide additional evidence of authenticity. The model also allows for the redaction of assertions in a verifiable way that is part of the provenance of the asset. Implementors in the CAI ecosystem might opt to use a DLT to federate their storage of assertions and claims to achieve an additional level of integrity and transparency. Because each assertion’s reference includes the assertion type, it is clear what type of information is being added. However, the CAI attribution model does not prevent a malicious user from stripping all of the CAI data from an asset and then adding new claims representing themselves as the originator. It is important to note that the redaction of assertions only applies to assertions that are part of the CAI data, and not all information in CAI claims is the same. To prevent unintended claim capture, it is recommended to be clear about what kind of CAI data to record.\n\nSources:\n[0] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[1] CAI claims can be augmented with human-generated review assertions so that fact checking professionals can provide additional evidence of authenticity.\n[2] NOTE: Assertion redacted only applies to assertions that are part of the CAI data.\n[3] Implementors in the CAI ecosystem might opt to use a DLT to federate their storage of assertions and claims to achieve an additional level of integrity and transparency.\n[4] The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset.\n[5] The CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator.\n[6] Because each assertion’s reference includes the assertion type, it is clear what type of information (eg.","system":"gpt_retrieval"},{"id":19,"text":"The CAI assertion and claim model allows for any type of assertion to be added at any time [1]. As a capture device captures an image, it concurrently creates a set of assertions about the image such as capture location, equipment details, identity of the user, and perhaps a representative thumbnail [2]. These assertions are embedded in the asset, and a claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user [3]. As edits are made, additional assertions are captured and stored in a cloud service, and a new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image [4] [5]. In addition, the redaction capability supports the inverse case where too much information was added and some needs to be removed [6].\n\nSources:\n[1] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[2] A capture device captures an image and concurrently creates a set of assertions about the image such as capture location, equipment details, identity of the user, and perhaps a representative thumbnail.\n[3] A claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user.\n[4] As edits are made, additional assertions are captured and stored in a cloud service.\n[5] This new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image.\n[6] In addition, the redaction capability supports the inverse case where too much information was added and some needs to be removed."}],"qaTask":[{"id":6,"question":"What is CAI and what is its purpose in digital content attribution?","answer":"CAI stands for Content Authenticity Initiative. Its purpose is to develop industry standards for content attribution, which includes creating a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio), and streaming content. The CAI aims to help content consumers make more informed decisions about what to trust by augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be. The creative chooses distribution points that support the CAI to ensure their attribution information remains intact. As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution. The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling. CAI specifications must respect the common privacy concerns of creators, publishers, and consumers of content. Since CAI data can contain a depth of detail that is not always relevant for all viewers, a UX based on the idea of progressive disclosure is envisaged. It is important for users to understand how CAI works, what the disclosed information means, and more.\n\nSources:\n[0] The initial mission of the CAI is to develop the industry standard for content attribution.\n[1] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[2] The creative chooses distribution points that support the CAI to ensure their attribution information remains intact.\n[3] As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution.\n[4] The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling.\n[5] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[6] CAI specifications must respect the common privacy concerns of creators, publishers and consumers of content.","system":"gpt_retrieval"},{"id":8,"question":"What is CAI and what is its purpose in digital content attribution?","answer":"The Content Authenticity Initiative (CAI) is a set of standards for digital content attribution that was announced by Adobe in partnership with The New York Times Company and Twitter [1]. The purpose of CAI is to provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today [2]. By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust [3]. The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content [4]. The CAI leverages existing standards for encoding, hashing, signing, compression and metadata, and allows for the redaction of assertions in a verifiable way that is also part of the provenance of the asset [5] [6] [7]. The CAI provides a specific type of assertion that references each ingredient's claims and assertions, whether they are embedded into the new composed document or stored in the cloud, and employs digital signature technology to ensure the integrity of the CAI information that is embedded into an asset, including the asset's data itself [8] [9]. The purpose of CAI is to establish trust and transparency in media by creating a rich, verifiable context that amplifies confidence in the authenticity of the asset [10] [11].\n\nSources:\n[1] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[2] We will provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today.\n[3] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[4] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[5] The CAI embraces existing standards.\n[6] This includes standards for encoding , hashing, signing, compression and metadata.\n[7] The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset.\n[8] The CAI provides for this with a specific type of assertion that references each ingredient’s claims and assertions, whether they are embedded into the new composed document or stored in the cloud.\n[9] In order to ensure the integrity of the CAI information that is embedded into an asset, including the asset’s data itself, (<https://en.wikipedia.org/wiki/Digital_signature>)digital signature technology is employed.\n[10] Together this collection of CAI data creates a rich, verifiable context that amplifies confidence in the authenticity of the asset.\n[11] With this first step towards an industry standard for digital content attribution, we look optimistically to a future with more trust and transparency in media."},{"id":11,"question":"What are some of the challenges to trust in media and how does CAI address them?","answer":"The sources suggest that there are extraordinary challenges to trust in media. To increase trust in media, it is important to engage diverse communities. The CAI aims to help content consumers make more informed decisions about what to trust by augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be. The CAI presents a set of standards that can be used to create and reveal attribution and history for various types of media. The CAI ecosystem is built around its own CAI Trust List for establishing trust. CAI claims can be augmented with human-generated review assertions so that fact-checking professionals can provide additional evidence of authenticity. The initial mission of the CAI is to develop the industry standard for content attribution. Since CAI data can contain a depth of detail that is not always relevant for all viewers, a UX based on the idea of progressive disclosure is envisaged.\n\nSources:\n[0] We are witnessing extraordinary challenges to trust in media.\n[1] Increasing trust in media requires the ongoing engagement of diverse communities.\n[2] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[3] The CAI does not prescribe a unified single platform for authenticity, but instead presents a set of standards that can be used to create and reveal attribution and history for images, documents, time-based media (video, audio) and streaming content.\n[4] To address these concerns, the CAI ecosystem is built around its own CAI Trust List for (<>)“Establishing Trust”.\n[5] CAI claims can be augmented with human-generated review assertions so that fact checking professionals can provide additional evidence of authenticity.\n[6] The initial mission of the CAI is to develop the industry standard for content attribution.","system":"gpt_retrieval"},{"id":13,"question":"What are some of the challenges to trust in media and how does CAI address them?","answer":"According to sources [1] [2] [3], there are growing challenges to trust in media due to the increasing velocity of digital content and the democratization of powerful creation and editing techniques. Social platforms also amplify the reach and influence of certain content via ever more complex and opaque algorithms, leading to mis-attributed and mis-contextualized content that spreads quickly [4]. The Content Authenticity Initiative (CAI), announced by Adobe in partnership with The New York Times Company and Twitter, aims to address these challenges by providing robust content attribution to ensure transparency, understanding, and ultimately, trust [5] [6] [7]. The CAI provides metadata that comprises information regarding asset creation, authorship, edit actions, capture device details, software used, and many other subjects [8]. This metadata creates a rich, verifiable context that amplifies confidence in the authenticity of the asset [9]. As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution [10]. A key point of differentiation for the asset with CAI information is that it empowers the source, rather than the institutions publishing the asset, to be the trusted entity [11]. By embracing ClaimReview and other standards like it, the CAI will support fact checking with rich metadata to optimize verification workflows [12]. The CAI assertion and claim model allows for any type of assertion to be added at any time, which addresses concerns about adding identity or any other form of identifying attribution to an asset at the time of capture that could lead to increased risk to content producers or others [13] [14]. While the CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator, trusted timestamps can be used to cast doubt on assets with deliberately altered histories [15] [16].\n\nSources:\n[1] We are witnessing extraordinary challenges to trust in media.\n[2] As social platforms amplify the reach and influence of certain content via ever more complex and opaque algorithms, mis-attributed and mis-contextualized content spreads quickly.\n[3] The news media industry is facing a growing sense of distrust in digital media and a changing distribution system as the number of people who receive news from social and nontraditional media sources grows.\n[4] As social platforms amplify the reach and influence of certain content via ever more complex and opaque algorithms, mis-attributed and mis-contextualized content spreads quickly.\n[5] With the increasing velocity of digital content and the democratization of powerful creation and editing techniques, robust content attribution is critical to ensure transparency, understanding, and ultimately, trust.\n[6] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[7] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter.\n[8] This metadata comprises information regarding asset creation, authorship, edit actions, capture device details, software used and many other subjects.\n[9] Together this collection of CAI data creates a rich, verifiable context that amplifies confidence in the authenticity of the asset.\n[10] As consumers view the content on social media platforms and/or the CAI website, the attribution details that they can see will start with the original capture and mitigate uncertainty for end users who may or may not trust the publishing institution.\n[11] A key point of differentiation for the asset with CAI information is that it empowers the source, rather than the institutions publishing the asset, to be the trusted entity.\n[12] By embracing ClaimReview and other standards like it, the CAI will support fact checking with rich metadata to optimize verification workflows.\n[13] In cases where adding identity (or any other form of identifying attribution) to an asset at the time of capture could lead to increased risk to content producers or others, it is important that assertions and claims can be added at some later time.\n[14] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[15] An actor could use watermarking technology to durably embed information (either perceptibly or imperceptibly) about the asset’s current claim.\n[16] Trusted timestamps can be used to cast doubt on assets with deliberately altered histories."},{"id":16,"question":"How does the CAI assertion and claim model allow for any type of assertion to be added at any time?","answer":"The CAI assertion and claim model allows for any type of assertion to be added at any time. Additionally, the CAI claims can be augmented with human-generated review assertions to provide additional evidence of authenticity. The model also allows for the redaction of assertions in a verifiable way that is part of the provenance of the asset. Implementors in the CAI ecosystem might opt to use a DLT to federate their storage of assertions and claims to achieve an additional level of integrity and transparency. Because each assertion’s reference includes the assertion type, it is clear what type of information is being added. However, the CAI attribution model does not prevent a malicious user from stripping all of the CAI data from an asset and then adding new claims representing themselves as the originator. It is important to note that the redaction of assertions only applies to assertions that are part of the CAI data, and not all information in CAI claims is the same. To prevent unintended claim capture, it is recommended to be clear about what kind of CAI data to record.\n\nSources:\n[0] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[1] CAI claims can be augmented with human-generated review assertions so that fact checking professionals can provide additional evidence of authenticity.\n[2] NOTE: Assertion redacted only applies to assertions that are part of the CAI data.\n[3] Implementors in the CAI ecosystem might opt to use a DLT to federate their storage of assertions and claims to achieve an additional level of integrity and transparency.\n[4] The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset.\n[5] The CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator.\n[6] Because each assertion’s reference includes the assertion type, it is clear what type of information (eg.","system":"gpt_retrieval"},{"id":18,"question":"How does the CAI assertion and claim model allow for any type of assertion to be added at any time?","answer":"The CAI assertion and claim model allows for any type of assertion to be added at any time [1]. As a capture device captures an image, it concurrently creates a set of assertions about the image such as capture location, equipment details, identity of the user, and perhaps a representative thumbnail [2]. These assertions are embedded in the asset, and a claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user [3]. As edits are made, additional assertions are captured and stored in a cloud service, and a new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image [4] [5]. In addition, the redaction capability supports the inverse case where too much information was added and some needs to be removed [6].\n\nSources:\n[1] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[2] A capture device captures an image and concurrently creates a set of assertions about the image such as capture location, equipment details, identity of the user, and perhaps a representative thumbnail.\n[3] A claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user.\n[4] As edits are made, additional assertions are captured and stored in a cloud service.\n[5] This new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image.\n[6] In addition, the redaction capability supports the inverse case where too much information was added and some needs to be removed."},{"id":20,"question":"which companies are part of CAI?","answer":"There is no information in the given sources about which companies are part of CAI. The sources mainly discuss the CAI's mission to develop industry standards for content attribution, the use of CAI rules and trust lists to ensure reliable retrieval of CAI claims, and the need for CAI specifications to consider the needs of users worldwide. The sources also mention the potential for newsrooms to vouch for the legitimacy of assets and add post-hoc CAI assertions. However, there is no mention of any specific companies that are part of CAI.\n\nSources:\n[0] Not all information in CAI claims is the same.\n[1] The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling.\n[2] To address these concerns, the CAI ecosystem is built around its own CAI Trust List for (<>)“Establishing Trust”.\n[3] The initial mission of the CAI is to develop the industry standard for content attribution.\n[4] The CAI embraces existing standards.\n[5] Here, the lack of end-to-end CAI compliance could be addressed by having the newsroom itself vouch for the legitimacy of assets and add time and location as post-hoc CAI assertions.\n[6] CAI specifications must take into consideration the needs of interested users throughout the world.\n[7] This model allows CAI to provide\n[8] While not part of the core CAI infrastructure, such solutions easily integrate with CAI and provide great utility."},{"id":21,"question":"which companies are part of CAI?","answer":"Adobe, The New York Times Company, and Twitter are part of the Content Authenticity Initiative (CAI) [1].\n\nSources:\n[1] At Adobe MAX 2019, the (<https://theblog.adobe.com/content-authenticity-initiative/>)Content Authenticity Initiative (CAI) was announced by Adobe in partnership with (<https://www.nytco.com/>)The New York Times Company and (<https://www.twitter.com/>)Twitter."},{"id":22,"question":"how can I validate if a piece of content is authentic or not?","answer":"To validate if a piece of content is authentic or not, there are several methods that can be used. One approach is through the Content Authenticity Initiative (CAI), which seeks to address the issue of content authenticity at scale. The CAI provides a visual indication that CAI data is present and verified, but it does not indicate whether the content is authentic. Another method is through the validation of claims and assertions, which can be embedded into the asset itself using a standard assertion type that contains a ClaimReview instance. This enables additional checks related to the context where the asset appears. Additionally, a combination of algorithmic identification and human-centered verification of intentionally misleading content can be used to reduce the amount of inauthentic content. It is important to note that without attribution information, publishers and consumers lack critical context for determining the authenticity of media. Finally, NGOs and media outlets can also enter their own verification process to ensure the authenticity of content.\n\nSources:\n[0] The Content Authenticity Initiative\n[1] Validation of Claims and Assertions\n[2] We seek to address the issue of content authenticity at scale.\n[3] For that reason, it is important that if a visual indication is associated with a valid asset, it should indicate only that CAI data is present and verified, and should not appear to indicate whether the content is authentic.\n[4] Through a combination of algorithmic identification and human-centered verification of intentionally misleading content the amount of inauthentic content can be reduced.\n[5] Without this attribution information, publishers and consumers lack critical context for determining the authenticity of media.\n[6] standard assertion type that contains a ClaimReview instance, these fact checks can now be embedded into the asset itself, enabling additional checks related to the context where the asset appears."},{"id":23,"question":"how can I validate if a piece of content is authentic or not?","answer":"The Content Authenticity Initiative (CAI) aims to provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today [1]. By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust [2]. Content with attribution exposes indicators of authenticity so that consumers can have awareness of who has altered content and what exactly has been changed [3]. The CAI allows for the redaction of assertions in a verifiable way that is also part of the provenance of the asset [4]. Trusted timestamps can be used to cast doubt on assets with deliberately altered histories [5]. To validate the authenticity of a piece of content, one can interact with the visual indicator to learn about the image's history. The most recent claim is retrieved and verified along with the entire chain of claims and their component assertions [6]. Additionally, various analysts from fact-checking organizations will verify the CAI data present in the asset, correlate it to any associated article, and then add their own labels and clarifications to it [7].\n\nSources:\n[1] We will provide a layer of robust, tamper-evident attribution and history data built upon XMP, Schema.org and other metadata standards that goes far beyond common uses today.\n[2] By augmenting subjective judgments about authenticity with objective facts about how a piece of content came to be, the CAI aims to help content consumers make more informed decisions about what to trust.\n[3] Content with attribution exposes indicators of authenticity so that consumers can have awareness of who has altered content and what exactly has been changed.\n[4] The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset.\n[5] Trusted timestamps can be used to cast doubt on assets with deliberately altered histories.\n[6] The most recent claim is retrieved and verified along with the entire chain of claims and their component assertions (see (<>)“Figure 2: Validating Claims”).\n[7] As required, various analysts from fact-checking organizations will verify the CAI data present in the asset, correlate it to any associated article, and then add their own labels and clarifications to it."},{"id":24,"question":"what is a \"claim\" in the context of CAI?","answer":"In the context of CAI, a \"claim\" is a digitally signed data structure that represents a set of assertions along with one or more cryptographic hashes on the data of an asset. The CAI assertion and claim model allows for any type of assertion to be added at any time, and the CAI claims can be augmented with human-generated review assertions to provide additional evidence of authenticity. Each new claim refers to the previous claim, thus creating a chain of provenance for the asset. The CAI allows for the redaction of these assertions in a verifiable way that is also part of the provenance of the asset. However, the CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator. When identical assets with different claim histories are encountered, the earlier CAI claims are likely to be trustworthy while the later ones may represent an attempt to alter history. It is important to be careful about what kind of CAI data to record to prevent unintended claim capture. The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling.\n\nSources:\n[0] Not all information in CAI claims is the same.\n[1] CAI claims can be augmented with human-generated review assertions so that fact checking professionals can provide additional evidence of authenticity.\n[2] The CAI assertion and claim model allows for any type of assertion to be added at any time.\n[3] A claim is a digitally signed data structure that represents a set of assertions along with one or more cryptographic hashes on the data of an asset.\n[4] For example, when identical assets with different claim histories are encountered, the earlier CAI claims are likely to be trustworthy while the later ones may represent an attempt to alter history.\n[5] The CAI attribution model does not prevent a malicious user from stripping all of the CAI data (claims and assertions) from an asset and then adding new claims representing themselves as the originator.\n[6] The CAI leverages its standard rules to ensure that the CAI claim can be reliably retrieved using existing technology including a variety of open source tooling.\n[7] Each new claim refers to the previous claim, thus creating a chain of provenance for the asset (see (<>)“Figure 1: Creating a Claim”)."},{"id":25,"question":"what is a \"claim\" in the context of CAI?","answer":"In the context of CAI, a \"claim\" is a digitally signed data structure that represents a set of assertions along with one or more cryptographic hashes on the data of an asset [1]. Assertions are cryptographically hashed and their hashes are gathered together into a claim [2]. Each new claim refers to the previous claim, thus creating a chain of provenance for the asset [3]. The signature ensures the integrity of the claim and makes the system tamper-evident [4]. A claim can be either directly or indirectly embedded into an asset as it moves through the life of the asset [5]. A claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user [6]. The claim is then embedded into the image and a reference to it stored in the asset’s metadata [7]. Upon image export, these are gathered together as part of a second claim along with the hash of the updated image [8]. This new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image [9]. The CAI assertion and claim model allows for any type of assertion to be added at any time [10].\n\nSources:\n[1] A claim is a digitally signed data structure that represents a set of assertions along with one or more cryptographic hashes on the data of an asset.\n[2] Assertions are cryptographically hashed and their hashes are gathered together into a claim.\n[3] Each new claim refers to the previous claim, thus creating a chain of provenance for the asset (see (<>)“Figure 1: Creating a Claim”).\n[4] The signature ensures the integrity of the claim and makes the system tamper-evident.\n[5] A claim can be either directly or indirectly embedded into an asset as it moves through the life of the asset.\n[6] A claim, referring to the set of assertions and including a hash of the image, is created and cryptographically signed by a trusted signing authority on behalf of the user.\n[7] The claim is then embedded into the image and a reference to it stored in the asset’s metadata (see (<>)“Figure 1: Creating a Claim”).\n[8] Upon image export, these are gathered together as part of a second claim along with the hash of the updated image.\n[9] This new claim (which is also stored in the cloud) refers to the prior claim, therefore ensuring that all assertions from both claims are accessible via the exported image without any link to the prior version of the image.\n[10] The CAI assertion and claim model allows for any type of assertion to be added at any time."}]}}